{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras implementation of https://junyanz.github.io/CycleGAN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='tensorflow' # can choose theano, tensorflow, cntk\n",
    "os.environ['THEANO_FLAGS']='floatX=float32,device=cuda,optimizer=fast_run,dnn.library_path=/usr/lib'\n",
    "#os.environ['THEANO_FLAGS']='floatX=float32,device=cuda,optimizer=fast_compile,dnn.library_path=/usr/lib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "if os.environ['KERAS_BACKEND'] =='theano':\n",
    "    channel_axis=1\n",
    "    K.set_image_data_format('channels_first')\n",
    "    channel_first = True\n",
    "else:\n",
    "    K.set_image_data_format('channels_last')\n",
    "    channel_axis=-1\n",
    "    channel_first = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Input, Dropout\n",
    "from keras.layers import Conv2DTranspose, Reshape, Activation, Cropping2D, Flatten\n",
    "from keras.layers import Concatenate, ZeroPadding2D, Dense\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights initializations\n",
    "# bias are initailized as 0\n",
    "def __conv_init(a):\n",
    "    print(\"conv_init\", a)\n",
    "    k = RandomNormal(0, 0.02)(a) # for convolution kernel\n",
    "    k.conv_weight = True    \n",
    "    return k\n",
    "conv_init = RandomNormal(0, 0.02)\n",
    "gamma_init = RandomNormal(1., 0.02) # for batch normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACK speed up theano\n",
    "if K._BACKEND == 'theano':\n",
    "    import keras.backend.theano_backend as theano_backend\n",
    "    def _preprocess_conv2d_kernel(kernel, data_format):\n",
    "        #return kernel\n",
    "        if hasattr(kernel, \"original\"):\n",
    "            print(\"use original\")\n",
    "            return kernel.original\n",
    "        elif hasattr(kernel, '_keras_shape'):\n",
    "            s = kernel._keras_shape\n",
    "            print(\"use reshape\",s)\n",
    "            kernel = kernel.reshape((s[3], s[2],s[0], s[1]))\n",
    "        else:\n",
    "            kernel = kernel.dimshuffle((3, 2, 0, 1))\n",
    "        return kernel\n",
    "    theano_backend._preprocess_conv2d_kernel = _preprocess_conv2d_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic discriminator\n",
    "def conv2d(f, *a, **k):\n",
    "    return Conv2D(f, kernel_initializer = conv_init, *a, **k)\n",
    "def batchnorm():\n",
    "    return BatchNormalization(momentum=0.9, axis=channel_axis, epsilon=1.01e-5,\n",
    "                                   gamma_initializer = gamma_init)\n",
    "def BASIC_D(nc_in, ndf, input_size = (None, None), max_layers=3, use_sigmoid=True):\n",
    "    \"\"\"DCGAN_D(nc, ndf, max_layers=3)\n",
    "       nc: channels\n",
    "       ndf: filters of the first layer\n",
    "       max_layers: max hidden layers\n",
    "    \"\"\"    \n",
    "    if channel_first:\n",
    "        input_a =  Input(shape=(nc_in, *input_size))\n",
    "    else:\n",
    "        input_a = Input(shape=(*input_size, nc_in))\n",
    "    _ = input_a\n",
    "    _ = conv2d(ndf, kernel_size=4, strides=2, padding=\"same\", name = 'First') (_)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    for layer in range(1, max_layers):        \n",
    "        out_feat = ndf * min(2**layer, 8)\n",
    "        _ = conv2d(out_feat, kernel_size=4, strides=2, padding=\"same\", \n",
    "                   use_bias=False, name = 'pyramid.{0}'.format(layer)             \n",
    "                        ) (_)\n",
    "        _ = batchnorm()(_, training=1)        \n",
    "        _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    out_feat = ndf*min(2**max_layers, 8)\n",
    "    _ = ZeroPadding2D(1)(_)\n",
    "    _ = conv2d(out_feat, kernel_size=4,  use_bias=False, name = 'pyramid_last') (_)\n",
    "    _ = batchnorm()(_, training=1)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    # final layer\n",
    "    _ = ZeroPadding2D(1)(_)\n",
    "    _ = conv2d(1, kernel_size=4, name = 'final'.format(out_feat, 1)) (_)    \n",
    "    \n",
    "    _ = Flatten(name = 'flatten') (_)\n",
    "    _ = Dense(1, name = 'final_dense', activation = \"sigmoid\" if use_sigmoid else None) (_)\n",
    "    \n",
    "    return Model(inputs=[input_a], outputs=_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNET_G(isize, nc_in=3, nc_out=3, ngf=64, fixed_input_size=True):    \n",
    "    max_nf = 8*ngf    \n",
    "    def block(x, s, nf_in, use_batchnorm=True, nf_out=None, nf_next=None):\n",
    "        # print(\"block\",x,s,nf_in, use_batchnorm, nf_out, nf_next)\n",
    "        assert s>=2 and s%2==0\n",
    "        if nf_next is None:\n",
    "            nf_next = min(nf_in*2, max_nf)\n",
    "        if nf_out is None:\n",
    "            nf_out = nf_in\n",
    "        x = conv2d(nf_next, kernel_size=4, strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'conv_{0}'.format(s)) (x)\n",
    "        if s>2:\n",
    "            if use_batchnorm:\n",
    "                x = batchnorm()(x, training=1)\n",
    "            x2 = LeakyReLU(alpha=0.2)(x)\n",
    "            x2 = block(x2, s//2, nf_next)\n",
    "            x = Concatenate(axis=channel_axis)([x, x2])            \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2DTranspose(nf_out, kernel_size=4, strides=2,\n",
    "                            use_bias=not use_batchnorm,\n",
    "                            kernel_initializer = conv_init,          \n",
    "                            name = 'convt.{0}'.format(s))(x)        \n",
    "        x = Cropping2D(1)(x)\n",
    "        if use_batchnorm:\n",
    "            x = batchnorm()(x, training=1)\n",
    "        if s <=8:\n",
    "            x = Dropout(0.5)(x, training=1)\n",
    "        return x\n",
    "    \n",
    "    s = isize if fixed_input_size else None\n",
    "    if channel_first:\n",
    "        _ = inputs = Input(shape=(nc_in, s, s))\n",
    "    else:\n",
    "        _ = inputs = Input(shape=(s, s, nc_in))        \n",
    "    _ = block(_, isize, nc_in, False, nf_out=nc_out, nf_next=ngf)\n",
    "    _ = Activation('tanh')(_)\n",
    "    return Model(inputs=inputs, outputs=[_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNET_G_SM(isize, nc_in=3, nc_out=3, ngf=64, fixed_input_size=True):    \n",
    "    max_nf = 8*ngf    \n",
    "    def block(x, s, nf_in, use_batchnorm=True, nf_out=None, nf_next=None):\n",
    "        # print(\"block\",x,s,nf_in, use_batchnorm, nf_out, nf_next)\n",
    "        assert s>=2 and s%2==0\n",
    "        if nf_next is None:\n",
    "            nf_next = min(nf_in*2, max_nf)\n",
    "        if nf_out is None:\n",
    "            nf_out = nf_in\n",
    "        x = conv2d(nf_next, kernel_size=4, strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'conv_{0}'.format(s)) (x)\n",
    "        if s>2:\n",
    "            if use_batchnorm:\n",
    "                x = batchnorm()(x, training=1)\n",
    "            x2 = LeakyReLU(alpha=0.2)(x)\n",
    "            x2 = block(x2, s//2, nf_next)\n",
    "            x = Concatenate(axis=channel_axis)([x, x2])            \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2DTranspose(nf_out, kernel_size=4, strides=2,\n",
    "                            use_bias=not use_batchnorm,\n",
    "                            kernel_initializer = conv_init,          \n",
    "                            name = 'convt.{0}'.format(s))(x)        \n",
    "        x = Cropping2D(1)(x)\n",
    "        if use_batchnorm:\n",
    "            x = batchnorm()(x, training=1)\n",
    "        if s <=8:\n",
    "            x = Dropout(0.5)(x, training=1)\n",
    "        return x\n",
    "    \n",
    "    s = isize if fixed_input_size else None\n",
    "    if channel_first:\n",
    "        _ = inputs = Input(shape=(nc_in, s, s))\n",
    "    else:\n",
    "        _ = inputs = Input(shape=(s, s, nc_in))        \n",
    "    _ = block(_, isize, nc_in, False, nf_out=ngf, nf_next=ngf)\n",
    "    _ = Activation('relu')(_)\n",
    "    _ = Conv2DTranspose(ngf, kernel_size=(13, 4), strides=(1, 2),\n",
    "                            use_bias=True,\n",
    "                            kernel_initializer = conv_init,\n",
    "                            name = 'convt.fin')(_)\n",
    "    _ = Cropping2D((0, 1))(_)\n",
    "    \n",
    "    _ = Activation(\"relu\")(_)\n",
    "    _ = Conv2DTranspose(ngf//2, kernel_size=4, strides=2,\n",
    "                        use_bias=True,\n",
    "                        kernel_initializer = conv_init,          \n",
    "                        name = 'convt.finfin')(_)        \n",
    "    _ = Cropping2D(1)(_)\n",
    "    _ = Activation('relu')(_)\n",
    "    _ = Conv2DTranspose(nc_out, kernel_size=(3, 4), strides=(1, 2),\n",
    "                        use_bias=True,\n",
    "                        kernel_initializer = conv_init,          \n",
    "                        name = 'convt.finfinfin')(_)        \n",
    "    _ = Cropping2D(1)(_)\n",
    "    _ = Activation('tanh')(_)\n",
    "    return Model(inputs=inputs, outputs=[_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNET_G_MS(isize, nc_in=1, nc_out=3, ngf=64, fixed_input_size=True):    \n",
    "    max_nf = 8*ngf    \n",
    "    def block(x, s, nf_in, use_batchnorm=True, nf_out=None, nf_next=None):\n",
    "        # print(\"block\",x,s,nf_in, use_batchnorm, nf_out, nf_next)\n",
    "        assert s>=2 and s%2==0\n",
    "        if nf_next is None:\n",
    "            nf_next = min(nf_in*2, max_nf)\n",
    "        if nf_out is None:\n",
    "            nf_out = nf_in\n",
    "        x = conv2d(nf_next, kernel_size=4, strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'conv_{0}'.format(s)) (x)\n",
    "        if s>2:\n",
    "            if use_batchnorm:\n",
    "                x = batchnorm()(x, training=1)\n",
    "            x2 = LeakyReLU(alpha=0.2)(x)\n",
    "            x2 = block(x2, s//2, nf_next)\n",
    "            x = Concatenate(axis=channel_axis)([x, x2])            \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2DTranspose(nf_out, kernel_size=4, strides=2,\n",
    "                            use_bias=not use_batchnorm,\n",
    "                            kernel_initializer = conv_init,\n",
    "                            name = 'convt.{0}'.format(s))(x)        \n",
    "        x = Cropping2D(1)(x)\n",
    "        if use_batchnorm:\n",
    "            x = batchnorm()(x, training=1)\n",
    "        if s <=8:\n",
    "            x = Dropout(0.5)(x, training=1)\n",
    "        return x\n",
    "    \n",
    "    s = isize if fixed_input_size else None\n",
    "    if channel_first:\n",
    "        _ = inputs = Input(shape=(nc_in, *musicSize))\n",
    "    else:\n",
    "        _ = inputs = Input(shape=(*musicSize, nc_in))\n",
    "    _ = conv2d(ngf, kernel_size=4, strides=(1, 2), use_bias=True,\n",
    "                   padding=\"same\", name = 'conv_superfirst') (_)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    #_ = ZeroPadding2D(padding=(0, 1), data_format=None) (_)\n",
    "    _ = conv2d(ngf*2, kernel_size=4, strides=2, use_bias=True,\n",
    "                   padding=\"same\", name = 'conv_first') (_)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    _ = ZeroPadding2D(padding=(0, 1), data_format=None) (_)\n",
    "    _ = conv2d(ngf*2, kernel_size=(13, 4), strides=(1,2), use_bias=True,\n",
    "               padding=\"valid\", name = 'conv_firstfirst') (_)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    _ = block(_, isize, ngf*2, False, nf_out=nc_out, nf_next=ngf)\n",
    "    _ = Activation('tanh')(_)\n",
    "    return Model(inputs=inputs, outputs=[_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_s = 3\n",
    "nc_m = 1\n",
    "ngf = 64\n",
    "ndf = 128\n",
    "\n",
    "spriteSize = (32, 32)\n",
    "musicSize = (88, 256)\n",
    "fs = 32\n",
    "snap_to = 1 # snaps to every 1/4 of a second\n",
    "snap_factor = 1 / snap_to\n",
    "dur = 8.0\n",
    "pitch_range = (21, 109)\n",
    "binary_music = True\n",
    "\n",
    "use_lsgan = False\n",
    "λ = 10 if use_lsgan else 100\n",
    "md_weight = 1\n",
    "mg_weight = 1.2\n",
    "\n",
    "continue_training = False\n",
    "batchSize = 4\n",
    "lrD = 2e-4\n",
    "lrG = 2e-4\n",
    "\n",
    "assert((fs // snap_factor) * snap_factor == fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_32 (Conv2D)                (None, 16, 16, 64)   3136        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 16, 16, 64)   0           conv_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 8, 8, 128)    131072      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 8, 128)    512         conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 8, 8, 128)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 4, 4, 256)    524288      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4, 4, 256)    1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 4, 4, 256)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 2, 2, 512)    2097152     leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2, 2, 512)    2048        conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 2, 2, 512)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 1, 1, 512)    4194816     leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 1, 512)    0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convt.2 (Conv2DTranspose)       (None, 4, 4, 512)    4194304     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 2, 2, 512)    0           convt.2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2, 2, 512)    2048        cropping2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2, 2, 512)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 2, 1024)   0           batch_normalization_3[0][0]      \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2, 2, 1024)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.4 (Conv2DTranspose)       (None, 6, 6, 256)    4194304     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)       (None, 4, 4, 256)    0           convt.4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 4, 4, 256)    1024        cropping2d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4, 4, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 4, 512)    0           batch_normalization_2[0][0]      \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 4, 4, 512)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.8 (Conv2DTranspose)       (None, 10, 10, 128)  1048576     activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)       (None, 8, 8, 128)    0           convt.8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 128)    512         cropping2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8, 8, 128)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 256)    0           batch_normalization_1[0][0]      \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 8, 256)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.16 (Conv2DTranspose)      (None, 18, 18, 64)   262144      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_4 (Cropping2D)       (None, 16, 16, 64)   0           convt.16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   256         cropping2d_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 128)  0           conv_32[0][0]                    \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 128)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.32 (Conv2DTranspose)      (None, 34, 34, 64)   131136      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_5 (Cropping2D)       (None, 32, 32, 64)   0           convt.32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 64)   0           cropping2d_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "convt.fin (Conv2DTranspose)     (None, 44, 66, 64)   213056      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_6 (Cropping2D)       (None, 44, 64, 64)   0           convt.fin[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 44, 64, 64)   0           cropping2d_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "convt.finfin (Conv2DTranspose)  (None, 90, 130, 32)  32800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_7 (Cropping2D)       (None, 88, 128, 32)  0           convt.finfin[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 88, 128, 32)  0           cropping2d_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "convt.finfinfin (Conv2DTranspos (None, 90, 258, 1)   385         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_8 (Cropping2D)       (None, 88, 256, 1)   0           convt.finfinfin[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 88, 256, 1)   0           cropping2d_8[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 17,034,593\n",
      "Trainable params: 17,030,881\n",
      "Non-trainable params: 3,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "netGM = UNET_G_SM(32, nc_s, nc_m, ngf) #netGA\n",
    "netGM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 88, 256, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_superfirst (Conv2D)        (None, 88, 128, 64)  1088        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 88, 128, 64)  0           conv_superfirst[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_first (Conv2D)             (None, 44, 64, 128)  131200      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 44, 64, 128)  0           conv_first[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 44, 66, 128)  0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_firstfirst (Conv2D)        (None, 32, 32, 128)  852096      zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 128)  0           conv_firstfirst[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_32 (Conv2D)                (None, 16, 16, 64)   131136      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 64)   0           conv_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 8, 8, 128)    131072      leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 128)    512         conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 8, 8, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 4, 4, 256)    524288      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 256)    1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 4, 4, 256)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 2, 2, 512)    2097152     leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 2, 512)    2048        conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 2, 2, 512)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 1, 1, 512)    4194816     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1, 1, 512)    0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convt.2 (Conv2DTranspose)       (None, 4, 4, 512)    4194304     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_9 (Cropping2D)       (None, 2, 2, 512)    0           convt.2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 2, 2, 512)    2048        cropping2d_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2, 2, 512)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 2, 2, 1024)   0           batch_normalization_10[0][0]     \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 2, 2, 1024)   0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.4 (Conv2DTranspose)       (None, 6, 6, 256)    4194304     activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_10 (Cropping2D)      (None, 4, 4, 256)    0           convt.4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 256)    1024        cropping2d_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 4, 4, 256)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 4, 4, 512)    0           batch_normalization_9[0][0]      \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 512)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.8 (Conv2DTranspose)       (None, 10, 10, 128)  1048576     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_11 (Cropping2D)      (None, 8, 8, 128)    0           convt.8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 128)    512         cropping2d_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 8, 8, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 8, 8, 256)    0           batch_normalization_8[0][0]      \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 256)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.16 (Conv2DTranspose)      (None, 18, 18, 64)   262144      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_12 (Cropping2D)      (None, 16, 16, 64)   0           convt.16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         cropping2d_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 128)  0           conv_32[0][0]                    \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 128)  0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.32 (Conv2DTranspose)      (None, 34, 34, 3)    6147        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_13 (Cropping2D)      (None, 32, 32, 3)    0           convt.32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 3)    0           cropping2d_13[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 17,775,747\n",
      "Trainable params: 17,772,035\n",
      "Non-trainable params: 3,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "netGS = UNET_G_MS(32, nc_m, nc_s, ngf) #netGB\n",
    "netGS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 88, 256, 1)        0         \n",
      "_________________________________________________________________\n",
      "First (Conv2D)               (None, 44, 128, 128)      2176      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 44, 128, 128)      0         \n",
      "_________________________________________________________________\n",
      "pyramid.1 (Conv2D)           (None, 22, 64, 256)       524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 22, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 22, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "pyramid.2 (Conv2D)           (None, 11, 32, 512)       2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 11, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 11, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 13, 34, 512)       0         \n",
      "_________________________________________________________________\n",
      "pyramid_last (Conv2D)        (None, 10, 31, 1024)      8388608   \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 10, 31, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 10, 31, 1024)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 12, 33, 1024)      0         \n",
      "_________________________________________________________________\n",
      "final (Conv2D)               (None, 9, 30, 1)          16385     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 270)               0         \n",
      "_________________________________________________________________\n",
      "final_dense (Dense)          (None, 1)                 271       \n",
      "=================================================================\n",
      "Total params: 11,036,048\n",
      "Trainable params: 11,032,464\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "First (Conv2D)               (None, 16, 16, 128)       6272      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "pyramid.1 (Conv2D)           (None, 8, 8, 256)         524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "pyramid.2 (Conv2D)           (None, 4, 4, 512)         2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "pyramid_last (Conv2D)        (None, 3, 3, 1024)        8388608   \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 5, 5, 1024)        0         \n",
      "_________________________________________________________________\n",
      "final (Conv2D)               (None, 2, 2, 1)           16385     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "final_dense (Dense)          (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 11,039,878\n",
      "Trainable params: 11,036,294\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "netDM = BASIC_D(nc_m, ndf, input_size = musicSize, use_sigmoid = not use_lsgan) # netDA\n",
    "netDS = BASIC_D(nc_s, ndf, input_size = spriteSize, use_sigmoid = not use_lsgan) # netDB\n",
    "netDM.summary()\n",
    "netDS.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop, SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_lsgan:\n",
    "    loss_fn = lambda output, target : K.mean(K.abs(K.square(output-target)))\n",
    "else:\n",
    "    loss_fn = lambda output, target : -K.mean(K.log(output+1e-12)*target+K.log(1-output+1e-12)*(1-target))\n",
    "\n",
    "def cycle_variables(netG1, netG2):\n",
    "    real_input = netG1.inputs[0]\n",
    "    fake_output = netG1.outputs[0]\n",
    "    rec_input = netG2([fake_output])\n",
    "    fn_generate = K.function([real_input], [fake_output, rec_input])\n",
    "    return real_input, fake_output, rec_input, fn_generate\n",
    "\n",
    "real_M, fake_S, rec_M, cycleM_generate = cycle_variables(netGS, netGM)\n",
    "real_S, fake_M, rec_S, cycleS_generate = cycle_variables(netGM, netGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_loss(netD, real, fake, rec):\n",
    "    output_real = netD([real])\n",
    "    output_fake = netD([fake])\n",
    "    loss_D_real = loss_fn(output_real, K.ones_like(output_real))\n",
    "    loss_D_fake = loss_fn(output_fake, K.zeros_like(output_fake))\n",
    "    loss_G = loss_fn(output_fake, K.ones_like(output_fake))\n",
    "    loss_D = loss_D_real+loss_D_fake\n",
    "    loss_cyc = K.mean(K.abs(rec-real))\n",
    "    return loss_D, loss_G, loss_cyc\n",
    "\n",
    "loss_DM, loss_GM, loss_cycS = D_loss(netDM, real_M, fake_M, rec_M)\n",
    "loss_DS, loss_GS, loss_cycM = D_loss(netDS, real_S, fake_S, rec_S)\n",
    "loss_cyc = loss_cycM+loss_cycS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_G = loss_GM+loss_GS+λ*loss_cyc\n",
    "loss_D = loss_DM+loss_DS\n",
    "\n",
    "weightsD = netDM.trainable_weights + netDS.trainable_weights\n",
    "weightsG = netGM.trainable_weights + netGS.trainable_weights\n",
    "\n",
    "training_updates = Adam(lr=lrD, beta_1=0.5).get_updates(weightsD,[],loss_D)\n",
    "netD_train = K.function([real_M, real_S],[md_weight * loss_DM/2, loss_DS/2], training_updates)\n",
    "training_updates = Adam(lr=lrG, beta_1=0.5).get_updates(weightsG,[], loss_G)\n",
    "netG_train = K.function([real_M, real_S], [mg_weight * loss_GM, loss_GS, loss_cyc], training_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pretty_midi in c:\\users\\mmille95\\appdata\\local\\conda\\conda\\envs\\cyclegan\\lib\\site-packages (0.2.8)\n",
      "Requirement already satisfied: six in c:\\users\\mmille95\\appdata\\local\\conda\\conda\\envs\\cyclegan\\lib\\site-packages (from pretty_midi) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.7.0 in c:\\users\\mmille95\\appdata\\local\\conda\\conda\\envs\\cyclegan\\lib\\site-packages (from pretty_midi) (1.15.4)\n",
      "Requirement already satisfied: mido>=1.1.16 in c:\\users\\mmille95\\appdata\\local\\conda\\conda\\envs\\cyclegan\\lib\\site-packages (from pretty_midi) (1.2.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pretty_midi\n",
    "import pretty_midi\n",
    "\n",
    "def prepare_midi(pm, fs = 16, duration = 30.0, pitchrange = (0, 128)):\n",
    "    \"\"\" \n",
    "    Takes a given midi file name and returns a PrettyMIDI object and its piano roll. \n",
    "\n",
    "    Extended description of function. \n",
    "\n",
    "    Parameters: \n",
    "    name (str): Name of midi file\n",
    "    fs (int): Samples per sec\n",
    "    duration (float): duration of time to keep \n",
    "    pitchrange (tuple[int]): tuple of starting pitch and ending pitch. 0 to 127 possible\n",
    "\n",
    "    Returns: \n",
    "    (PrettyMIDI, numpyArray): prettymidi object and cropped piano roll array\n",
    "\n",
    "    \"\"\" \n",
    "\n",
    "    pmroll = pm.get_piano_roll(fs)[pitchrange[0] : pitchrange[1]]\n",
    "    if duration > 0:\n",
    "        pmroll = pmroll[:, 0 : int(duration * fs)]\n",
    "    return pmroll\n",
    "\n",
    "def to_midi(pr, fs = 8, pitchrange = (0, 128), force_velocity = False):\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    piano_program = pretty_midi.instrument_name_to_program('Acoustic Grand Piano')\n",
    "    piano = pretty_midi.Instrument(program = piano_program)\n",
    "    \n",
    "    pitch_start = pitchrange[0]\n",
    "    for p in range(len(pr)):\n",
    "        start = False\n",
    "        startTime = 0.0\n",
    "        v = 0\n",
    "        for t in range(len(pr[p])):\n",
    "            if not start and int(pr[p][t]) > 0:\n",
    "                start = True\n",
    "                v = int(pr[p][t])\n",
    "                startTime = t / fs\n",
    "            elif start and int(pr[p][t]) != v:\n",
    "                endTime = t / fs\n",
    "                vel = v\n",
    "                if force_velocity:\n",
    "                    vel = 125\n",
    "                _ = pretty_midi.Note(velocity = vel, \n",
    "                                    pitch = pitch_start + p, start = startTime, end = endTime)\n",
    "                piano.notes.append(_)\n",
    "                if int(pr[p][t]) == 0:\n",
    "                    start = False\n",
    "                else:\n",
    "                    startTime = endTime\n",
    "                    v = int(pr[p][t])\n",
    "    \n",
    "    pm.instruments.append(piano)\n",
    "    return pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pitch_occur(midis):\n",
    "    pitches = [0] * 128\n",
    "    for fn in midis:        \n",
    "        try:\n",
    "            _ = pretty_midi.PrettyMIDI(fn)\n",
    "            print(fn, \"\\n loading... loaded\")\n",
    "        except:\n",
    "            print(fn, \"\\n loading... ERROR\")\n",
    "        roll = prepare_midi(_, fs = 8, duration = 0.0)\n",
    "        for p in range(128):\n",
    "            if len(set(roll[p])) > 1:\n",
    "                pitches[p] += 1\n",
    "\n",
    "    for p in range(128):\n",
    "        print(p, pitches[p], sep=': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Removing songs that are too short]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmille95\\AppData\\Local\\conda\\conda\\envs\\cycleGAN\\lib\\site-packages\\pretty_midi\\pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-263  not big enough ( trainingSet/music\\vgpiano\\CastleVania_-_StageClear.mid )\n",
      "-197  not big enough ( trainingSet/music\\vgpiano\\cchitcat.mid )\n",
      "-288  not big enough ( trainingSet/music\\vgpiano\\command_melody_lozww_piano.mid )\n",
      "-7  not big enough ( trainingSet/music\\vgpiano\\Creation_piano_.mid )\n",
      "80  not big enough ( trainingSet/music\\vgpiano\\DKONG.mid )\n",
      "36  not big enough ( trainingSet/music\\vgpiano\\dk_title.mid )\n",
      "-324  not big enough ( trainingSet/music\\vgpiano\\GameOverPiano.mid )\n",
      "-160  not big enough ( trainingSet/music\\vgpiano\\inverted_song_time_piano.mid )\n",
      "-324  not big enough ( trainingSet/music\\vgpiano\\Mario_Dies_Super_Mario_World.mid )\n",
      "-237  not big enough ( trainingSet/music\\vgpiano\\mmx5bossintropianoversion.mid )\n",
      "-236  not big enough ( trainingSet/music\\vgpiano\\MP_Artifact_-_Piano_Only_-_By_DaDude.mid )\n",
      "-234  not big enough ( trainingSet/music\\vgpiano\\MP_Item_Acquired_-_Piano_Only_-_By_DaDude.mid )\n",
      "-77  not big enough ( trainingSet/music\\vgpiano\\Music_Box_Clock.mid )\n",
      "159  not big enough ( trainingSet/music\\vgpiano\\serenade_of_water-piano.mid )\n",
      "-224  not big enough ( trainingSet/music\\vgpiano\\sm1bwin.mid )\n",
      "-10  not big enough ( trainingSet/music\\vgpiano\\smb-starman-piano.mid )\n",
      "43  not big enough ( trainingSet/music\\vgpiano\\SMW-Donut.mid )\n",
      "-4  not big enough ( trainingSet/music\\vgpiano\\SON1TITLE.mid )\n",
      "-160  not big enough ( trainingSet/music\\vgpiano\\W2-Koopahari-v2.mid )\n",
      "121  not big enough ( trainingSet/music\\vgpiano\\yoshi17.mid )\n",
      "Num midi files:  698\n",
      "Num sprites:  2690\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from random import randint, shuffle\n",
    "\n",
    "def load_data(file_pattern):\n",
    "    return glob.glob(file_pattern, recursive = True)\n",
    "\n",
    "def read_image(fn, imgSize, augment=False):\n",
    "    im = Image.open(fn).convert(\"RGBA\")\n",
    "    im = im.resize(imgSize, Image.BILINEAR )\n",
    "    img = np.array(im, dtype=np.float64)\n",
    "    alphaLayer = img[:,:,3] / 255.0\n",
    "    img[:,:,0] *= alphaLayer\n",
    "    img[:,:,1] *= alphaLayer\n",
    "    img[:,:,2] *= alphaLayer\n",
    "    img = (img/255.0*2-1)[:,:,:3]\n",
    "    if augment and randint(0,1):\n",
    "        img=img[:,::-1]\n",
    "    if channel_first:        \n",
    "        img = np.moveaxis(img, 2, 0)\n",
    "    return img\n",
    "\n",
    "def read_midi(fn, imgSize, fs, duration, prange, augment=False):\n",
    "    try:\n",
    "        _ = pretty_midi.PrettyMIDI(fn)\n",
    "    except:\n",
    "        return None\n",
    "    roll = prepare_midi(_, fs, 0, prange)\n",
    "    window = int(fs * duration)\n",
    "    end = len(roll[0]) - int(5 * fs) - window\n",
    "    if end < int(5 * fs):\n",
    "        print(end, \" not big enough (\", fn, \")\")\n",
    "        return None\n",
    "    start = np.random.randint(int(5 * fs), end)\n",
    "    snap = fs // snap_factor\n",
    "    start = int((start // snap) * snap)\n",
    "    img = roll[:, start : start + window]\n",
    "    if binary_music:\n",
    "        img = np.clip(img, 0, 1)\n",
    "    else:\n",
    "        img = (img/128.0)\n",
    "    #if augment and randint(0,1):\n",
    "    #    img=img[:,::-1]\n",
    "    if channel_first:        \n",
    "        img = np.moveaxis(img, 2, 0)\n",
    "    if img.shape != imgSize:\n",
    "        print(\"[ERROR] Created an invalid shaped piece of music data! Size: \", img.shape, \" instead of \", imgSize)\n",
    "    return img\n",
    "\n",
    "data = \"sprites2music\"\n",
    "train_S = load_data('trainingSet/sprites/**/*.png')\n",
    "train_M = load_data('trainingSet/music/**/*.mid')\n",
    "\n",
    "print(\"[Removing songs that are too short]\")\n",
    "to_remove = []\n",
    "for m in train_M:\n",
    "    if read_midi(m, musicSize, fs, dur, pitch_range) is None:\n",
    "        to_remove.append(m)\n",
    "for m in to_remove:\n",
    "    train_M.remove(m)\n",
    "\n",
    "assert len(train_M) and len(train_S)\n",
    "\n",
    "shuffle(train_M)\n",
    "shuffle(train_S)\n",
    "\n",
    "print(\"Num midi files: \", len(train_M))\n",
    "print(\"Num sprites: \", len(train_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 trainingSet/music\\vgpiano\\Yamato_Region.mid\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x5760 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 256)\n"
     ]
    }
   ],
   "source": [
    "#show_pitch_occur(train_M)\n",
    "test = None\n",
    "while test is None:\n",
    "    n = np.random.randint(len(train_M))\n",
    "    print(n, train_M[n])\n",
    "    test = read_midi(train_M[n], musicSize, fs, dur, pitch_range)\n",
    "plt.figure(figsize = (40, 80))\n",
    "plt.imshow(test)\n",
    "plt.show()\n",
    "\n",
    "pm = to_midi(test, fs, pitch_range, force_velocity= binary_music)\n",
    "pm.write('test.mid')\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatchS(data, batchsize, imgSize = spriteSize, augment = False):\n",
    "    length = len(data)\n",
    "    epoch = i = 0\n",
    "    tmpsize = None    \n",
    "    while True:\n",
    "        size = tmpsize if tmpsize else batchsize\n",
    "        if i+size > length:\n",
    "            shuffle(data)\n",
    "            i = 0\n",
    "            epoch+=1        \n",
    "        rtn = [read_image(data[j], imgSize, augment) for j in range(i,i+size)]\n",
    "        i+=size\n",
    "        tmpsize = yield epoch, np.float32(rtn)       \n",
    "        \n",
    "def minibatchM(data, batchsize, imgSize = musicSize, augment = False):\n",
    "    length = len(data)\n",
    "    epoch = i = 0\n",
    "    tmpsize = None    \n",
    "    while True:\n",
    "        size = tmpsize if tmpsize else batchsize\n",
    "        if i+size > length:\n",
    "            shuffle(data)\n",
    "            i = 0\n",
    "            epoch+=1        \n",
    "        rtn = [read_midi(data[j], imgSize, fs, dur, pitch_range, augment) for j in range(i,i+size)]\n",
    "        i+=size\n",
    "        tmpsize = yield epoch, np.expand_dims(np.float32(rtn), -1)\n",
    "\n",
    "def minibatchMS(dataM, dataS, batchsize):\n",
    "    batchM=minibatchM(dataM, batchsize, augment=False)\n",
    "    batchS=minibatchS(dataS, batchsize, augment=True)\n",
    "    tmpsize = None\n",
    "    while True:        \n",
    "        ep1, M = batchM.send(tmpsize)\n",
    "        ep2, S = batchS.send(tmpsize)\n",
    "        tmpsize = yield max(ep1, ep2), M, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showX(X, imageWidth, imageHeight, nc, rows=1, figsize = (20, 40)):\n",
    "    assert X.shape[0]%rows == 0\n",
    "    cols = X.shape[0]//rows\n",
    "    plt.figure(figsize=figsize)\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            i = r*cols + c\n",
    "            int_X = X[i]\n",
    "            if (imageHeight, imageWidth) == spriteSize:\n",
    "                int_X = ((int_X+1)/2)\n",
    "            int_X = (int_X*255).clip(0,255).astype('uint8')\n",
    "            if channel_first:\n",
    "                int_X = np.moveaxis(int_X.reshape(-1,nc,imageWidth, imageHeight), 1, nc)\n",
    "            else:\n",
    "                int_X = int_X.reshape(-1, imageWidth, imageHeight, nc)\n",
    "            ax = plt.subplot(rows, cols, i+1)\n",
    "            ax.imshow(np.squeeze(int_X), cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\n",
    "            ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x2880 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x2880 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_batch = minibatchMS(train_M, train_S, 4)\n",
    "\n",
    "_, M, S = next(train_batch)\n",
    "showX(M, *musicSize, nc_m)\n",
    "showX(S, *spriteSize, nc_s)\n",
    "del train_batch, M, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showG(M,S):\n",
    "    def G(fn_generate, X):\n",
    "        fakes = []\n",
    "        recs = []\n",
    "        for i in range(X.shape[0]):\n",
    "            fake, rec = fn_generate([X[i:i+1]])\n",
    "            fakes.append(fake[0])\n",
    "            recs.append(rec[0])\n",
    "        return [np.array(fakes), np.array(recs)]\n",
    "    rM = G(cycleM_generate, M)\n",
    "    rS = G(cycleS_generate, S)\n",
    "    arr = [M,*rM,S,*rS]\n",
    "    for elem in arr:\n",
    "        print(elem.shape)\n",
    "        showX(elem, elem.shape[1], elem.shape[2], elem.shape[3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/350][25] Loss_D: 1.151778 0.947842 Loss_G: 31.349829 9.186726 loss_cyc 0.789517 0.267\n",
      "[0/350][50] Loss_D: 11.888472 1.682703 Loss_G: 5.088790 11.444822 loss_cyc 0.730092 0.381\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-2a8d5cbce498>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mniter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0merrDM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrDS\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnetD_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0merrDM_sum\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[0merrDM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-aab2b65e3506>\u001b[0m in \u001b[0;36mminibatchMS\u001b[1;34m(dataM, dataS, batchsize)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mtmpsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mep1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatchM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmpsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mep2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatchS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmpsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mtmpsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32myield\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mep1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mep2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-aab2b65e3506>\u001b[0m in \u001b[0;36mminibatchM\u001b[1;34m(data, batchsize, imgSize, augment)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mrtn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mread_midi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpitch_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mtmpsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32myield\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrtn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mminibatchMS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "t0 = time.time()\n",
    "niter = 350\n",
    "gen_iterations = 0\n",
    "epoch = 0\n",
    "errCyc_sum = errGM_sum = errGS_sum = errDM_sum = errDS_sum = 0\n",
    "\n",
    "past_epoch = 0\n",
    "display_iters = 25\n",
    "#val_batch = minibatch(valAB, 6, direction)\n",
    "train_batch = minibatchMS(train_M, train_S, batchSize)\n",
    "\n",
    "while epoch < niter: \n",
    "    epoch, M, S = next(train_batch)  \n",
    "    errDM, errDS  = netD_train([M, S])\n",
    "    errDM_sum +=errDM\n",
    "    errDS_sum +=errDS\n",
    "\n",
    "    # epoch, trainA, trainB = next(train_batch)\n",
    "    errGM, errGS, errCyc = netG_train([M, S])\n",
    "    errGM_sum += errGM\n",
    "    errGS_sum += errGS\n",
    "    errCyc_sum += errCyc\n",
    "    gen_iterations+=1\n",
    "    if gen_iterations%display_iters==0:\n",
    "        #if gen_iterations%(5*display_iters)==0:\n",
    "        #clear_output()\n",
    "        print('[%d/%d][%d] Loss_D: %f %f Loss_G: %f %f loss_cyc %f'\n",
    "        % (epoch, niter, gen_iterations, errDM_sum/display_iters, errDS_sum/display_iters,\n",
    "           errGM_sum/display_iters, errGS_sum/display_iters, \n",
    "           errCyc_sum/display_iters), \"%.3f\" % ((time.time()-t0)/60.0))\n",
    "        errCyc_sum = errGM_sum = errGS_sum = errDM_sum = errDS_sum = 0\n",
    "    if epoch != past_epoch:\n",
    "        _, M, S = train_batch.send(4)\n",
    "        showG(M,S)\n",
    "        if epoch == 270:\n",
    "            netDM.save('run07b_netDM')\n",
    "            netDS.save('run07b_netDS')\n",
    "            netGM.save('run07b_netGM')\n",
    "            netGS.save('run07b_netGS')\n",
    "        past_epoch = epoch\n",
    "        \n",
    "        \n",
    "_, M, S = train_batch.send(4)\n",
    "showG(M,S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all the things\n",
    "netDM.save('run07_netDM')\n",
    "netDS.save('run07_netDS')\n",
    "netGM.save('run07_netGM')\n",
    "netGS.save('run07_netGS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
